# -------------------------------
# ⚙️ 默认配置项
# -------------------------------

# Ollama 本地服务地址（未使用）
# DEFAULT_OLLAMA_URL = "http://localhost:11434/api/generate"

# 远程 Ollama 服务地址（Tunnelmole 公開URL）
DEFAULT_OLLAMA_URL = "http://byv6jp-ip-49-98-40-252.tunnelmole.net/api/generate"

# 默认使用的本地模型名称
DEFAULT_LOCAL_MODEL_NAME = "deepseek-r1"

# OpenAI 中继服务地址（如使用本地代理）
DEFAULT_OPENAI_RELAY_URL = "http://localhost:8000/ask"
