from fastapi import FastAPI, Request, HTTPException
from pydantic import BaseModel
from db.user import validate_login, get_token_count, deduct_token
import openai
import time
import os

app = FastAPI()

# -------------------------------
# ğŸ” è®¾ç½® OpenAI API å¯†é’¥
# -------------------------------
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
openai.api_key = api_key

# -------------------------------
# ğŸš¦ ç®€å•é¢‘ç‡é™åˆ¶ï¼ˆæ¯ IP æ¯åˆ†é’Ÿæœ€å¤š 3 æ¬¡ï¼‰
# -------------------------------
rate_limit = {}
MAX_REQUESTS = 3
WINDOW = 60  # ç§’

def check_rate_limit(ip: str) -> bool:
    now = time.time()
    history = rate_limit.get(ip, [])
    history = [t for t in history if now - t < WINDOW]
    if len(history) >= MAX_REQUESTS:
        return False
    history.append(now)
    rate_limit[ip] = history
    return True

# -------------------------------
# ğŸ“¥ ç™»å½•è¯·æ±‚ç»“æ„
# -------------------------------
class LoginRequest(BaseModel):
    username: str
    password: str

# -------------------------------
# ğŸ“¤ æ¨¡å‹è¯·æ±‚ç»“æ„
# -------------------------------
class Query(BaseModel):
    prompt: str
    username: str
    model: str = "gpt-3.5-turbo"
    temperature: float = 0.7

# -------------------------------
# ğŸ” ç™»å½•æ¥å£
# -------------------------------
@app.post("/login")
async def login(req: LoginRequest):
    result = validate_login(req.username, req.password)
    if result:
        return {"success": True, "role": result[0]}
    else:
        raise HTTPException(status_code=401, detail="ç™»å½•å¤±è´¥")

# -------------------------------
# ğŸ§  æ¨¡å‹è°ƒç”¨æ¥å£
# -------------------------------
@app.post("/ask")
async def ask_openai(query: Query, request: Request):
    ip = request.client.host
    username = query.username

    # ğŸ§¨ æ£€æŸ¥ä»¤ç‰Œ
    tokens = get_token_count(username)
    if tokens <= 0:
        raise HTTPException(status_code=403, detail="ä»¤ç‰Œå·²ç”¨å°½")

    # ğŸš¦ æ£€æŸ¥é¢‘ç‡é™åˆ¶
    if not check_rate_limit(ip):
        raise HTTPException(status_code=429, detail="è¯·æ±‚è¿‡äºé¢‘ç¹")

    # ğŸ§  è°ƒç”¨ OpenAI æ¨¡å‹
    try:
        response = openai.ChatCompletion.create(
            model=query.model,
            messages=[{"role": "user", "content": query.prompt}],
            temperature=query.temperature
        )
        result_text = response.choices[0].message.content

        # âœ… æ‰£é™¤ä»¤ç‰Œï¼ˆä»…åœ¨æˆåŠŸåï¼‰
        deduct_token(username)

        return {
            "success": True,
            "data": {
                "result": result_text,
                "tokens_left": tokens - 1
            }
        }

    except openai.error.OpenAIError as e:
        raise HTTPException(status_code=500, detail=f"æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception:
        raise HTTPException(status_code=500, detail="æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åå†è¯•")
